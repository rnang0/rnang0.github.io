<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>HBase数据库、Hive数据仓库 | rnang0 Blog</title><meta name="description" content="一、HBaseHBase 是一种分布式、可扩展、支持海量数据存储的 NoSQL 数据库。 1. 逻辑结构与物理存储结构（1）逻辑上，HBase 的数据模型同关系型数据库很类似，数据存储在一张表中，有行有列。 每个Region下，“行”就成了store，列则变成了列族。  （2）但从HBase 的底层物理存储结构（K-V）来看，HBase 更像是一个 multi-dimensional map。 S"><meta name="keywords" content="HBase,Hive"><meta name="author" content="rnang0"><meta name="copyright" content="rnang0"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="HBase数据库、Hive数据仓库"><meta name="twitter:description" content="一、HBaseHBase 是一种分布式、可扩展、支持海量数据存储的 NoSQL 数据库。 1. 逻辑结构与物理存储结构（1）逻辑上，HBase 的数据模型同关系型数据库很类似，数据存储在一张表中，有行有列。 每个Region下，“行”就成了store，列则变成了列族。  （2）但从HBase 的底层物理存储结构（K-V）来看，HBase 更像是一个 multi-dimensional map。 S"><meta name="twitter:image" content="https://gitee.com/rnang0/blogimage/raw/master/20210625163109.png"><meta property="og:type" content="article"><meta property="og:title" content="HBase数据库、Hive数据仓库"><meta property="og:url" content="http://rnang0.github.io/2021/06/09/HBase/"><meta property="og:site_name" content="rnang0 Blog"><meta property="og:description" content="一、HBaseHBase 是一种分布式、可扩展、支持海量数据存储的 NoSQL 数据库。 1. 逻辑结构与物理存储结构（1）逻辑上，HBase 的数据模型同关系型数据库很类似，数据存储在一张表中，有行有列。 每个Region下，“行”就成了store，列则变成了列族。  （2）但从HBase 的底层物理存储结构（K-V）来看，HBase 更像是一个 multi-dimensional map。 S"><meta property="og:image" content="https://gitee.com/rnang0/blogimage/raw/master/20210625163109.png"><meta property="article:published_time" content="2021-06-08T16:00:00.000Z"><meta property="article:modified_time" content="2021-06-25T11:37:22.719Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = 'false'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="canonical" href="http://rnang0.github.io/2021/06/09/HBase/"><link rel="next" title="大数据Hadoop" href="http://rnang0.github.io/2021/05/08/Hadoop/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: true,
  fancybox: false,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'none',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/autor.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">68</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">94</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-mars"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#一、HBase"><span class="toc-text">一、HBase</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-逻辑结构与物理存储结构"><span class="toc-text">1. 逻辑结构与物理存储结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-数据模型"><span class="toc-text">2. 数据模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-基本架构"><span class="toc-text">3. 基本架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-HBase-Shell-操作"><span class="toc-text">4. HBase Shell 操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-DDL操作"><span class="toc-text">4.1 DDL操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-DML操作"><span class="toc-text">4.2 DML操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-HBase架构原理"><span class="toc-text">5. HBase架构原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-读写流程"><span class="toc-text">6. 读写流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-JavaAPI操作HBase"><span class="toc-text">7. JavaAPI操作HBase</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-DDL的操作"><span class="toc-text">7.1 DDL的操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-DML的操作"><span class="toc-text">7.2 DML的操作</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#二、Hive"><span class="toc-text">二、Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Hive本质"><span class="toc-text">1. Hive本质</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-架构原理"><span class="toc-text">2. 架构原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Hive数据类型"><span class="toc-text">3. Hive数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-DDL操作"><span class="toc-text">4. DDL操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-DML操作"><span class="toc-text">5. DML操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HBase-与-Hive-的对比"><span class="toc-text">HBase 与 Hive 的对比</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://gitee.com/rnang0/blogimage/raw/master/20210625163109.png)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">rnang0 Blog</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-mars"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">HBase数据库、Hive数据仓库</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2021-06-09 00:00:00"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2021-06-09</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2021-06-25 19:37:22"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2021-06-25</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="一、HBase"><a href="#一、HBase" class="headerlink" title="一、HBase"></a>一、HBase</h1><p>HBase 是一种<strong>分布式</strong>、可扩展、支持海量数据存储的 <strong>NoSQL 数据库。</strong></p>
<h2 id="1-逻辑结构与物理存储结构"><a href="#1-逻辑结构与物理存储结构" class="headerlink" title="1. 逻辑结构与物理存储结构"></a>1. 逻辑结构与物理存储结构</h2><p>（1）逻辑上，HBase 的数据模型同关系型数据库很类似，数据存储在<strong>一张表中，有行有列。</strong></p>
<p><strong>每个Region下，“行”就成了store，列则变成了列族。</strong></p>
<p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625164911.png" alt="img"></p>
<p>（2）但从HBase 的底层物理存储结构（K-V）来看，HBase 更像是一个 multi-dimensional map。</p>
<p>StoreFile<strong>保存实际数据的物理文件</strong>，StoreFile 以 HFile 的形式<strong>存储在 HDFS 上</strong>。每个 Store 会有一个或多个 StoreFile（HFile），数据在每个 StoreFile 中都是有序的。</p>
<p>底层是存储一行的，<strong>rowkey - 列族 + 列名 + 时间戳 + 类型 + 值Value。</strong></p>
<p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625164929.png" alt="img"></p>
<h2 id="2-数据模型"><a href="#2-数据模型" class="headerlink" title="2. 数据模型"></a>2. 数据模型</h2><ul>
<li><p>NameSpace：命名空间，<strong>类似于关系型数据库的 DatabBase 概念</strong>，每个命名空间下有多个表。HBase 有两个自带的命名空间，分别是 <strong>hbase 和 default</strong>，<strong>hbase 中存放的是 HBase 内置的表，例如存储RegionServer信息的Meta表。</strong> default 表是用户默认使用的命名空间。</p>
</li>
<li><p>Region：类似于关系型数据库的<strong>表概念。</strong>不同的是，HBase 定义表时只需要声明列族即可，不需要声明具体的列。这意味着，往 HBase 写入数据时，字段可以动态、按需指定。因此，和关系型数据库相比，HBase 能够轻松应对字段变更的场景。</p>
</li>
<li><p>Row：HBase 表中的每行数据都由一个 <strong>RowKey</strong> 和多个 <strong>Column</strong>（列）组成，数据是按照 RowKey 的字典顺序存储的，并且查询数据时只能根据 RowKey 进行检索，所以 RowKey 的设计十分重要。</p>
</li>
<li><p>Column：HBase 中的每个列都由 Column Family(列族)和 Column Qualifier（列限定符）进行限定，例如 info：name，info：age。建表时，只需指明列族，而列限定符无需预先定义。</p>
</li>
<li><p>TimeStamp：<strong>用于标识数据的不同版本（version），每条数据写入时，如果不指定时间戳，系统会自动为其加上该字段，其值为写入 HBase 的时间。</strong></p>
</li>
<li><p>Cell ：由{rowkey, column Family：column Qualifier, time Stamp} 唯一确定的单元。cell 中的数据是没有类型的，全部是字节码形式存贮。</p>
</li>
</ul>
<h2 id="3-基本架构"><a href="#3-基本架构" class="headerlink" title="3. 基本架构"></a>3. 基本架构</h2><p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625170028.png" alt="1"></p>
<ul>
<li><p>Zookeeper：HBase 通过 Zookeeper 来做 <strong>Master 的高可用</strong>、<strong>RegionServer 的监控</strong>、元数据的<strong>入口</strong>以及集群配置的维护等工作。</p>
</li>
<li><p>Region Server 为 Region 的管理者，其实现类为 HRegionServer，主要作用如下: <strong>对于数据的操作</strong>：get, put, delete；</p>
<p>对于Region 的操作：splitRegion、compactRegion。</p>
</li>
<li><p><strong>Master：Master 是所有 Region Server 的管理者</strong>，其实现类为 HMaster，主要作用是对于表的操作：create, delete, alter</p>
<p> 对于RegionServer 的操作：<strong>分配regions 到每个RegionServer，</strong>监控每个RegionServer的状态，负载均衡和故障转移。</p>
</li>
<li><p>HDFS：为 HBase 提供最终的<strong>底层数据存储服务</strong>，同时为HBase 提供高可用的支持。</p>
</li>
</ul>
<h2 id="4-HBase-Shell-操作"><a href="#4-HBase-Shell-操作" class="headerlink" title="4. HBase Shell 操作"></a>4. HBase Shell 操作</h2><p>在解压完HBase后，配置好配置文件，然后启动zk，hadoop，然后启动hbase，最后进入客户端<code>bin/hbase shell</code></p>
<h3 id="4-1-DDL操作"><a href="#4-1-DDL操作" class="headerlink" title="4.1 DDL操作"></a>4.1 DDL操作</h3><ol>
<li>创建表create</li>
</ol>
<p><code>hbase(main):002:0&gt; create &#39;student&#39;,&#39;info&#39;</code></p>
<ol start="2">
<li>插入put数据到表</li>
</ol>
<p><code>hbase(main):003:0&gt; put &#39;student&#39;,&#39;1001&#39;,&#39;info:sex&#39;,&#39;male&#39;</code></p>
<p><code>hbase(main):004:0&gt; put &#39;student&#39;,&#39;1001&#39;,&#39;info:age&#39;,&#39;18&#39;</code></p>
<ol start="3">
<li>扫描scan查看表数据</li>
</ol>
<p><code>hbase(main):008:0&gt; scan &#39;student&#39; hbase(main):009:0&gt; scan &#39;student&#39;,{STARTROW =&gt; &#39;1001&#39;, STOPROW    =&gt; &#39;1001&#39;}</code> <code>hbase(main):010:0&gt; scan &#39;student&#39;,{STARTROW =&gt; &#39;1001&#39;}</code></p>
<ol start="4">
<li><strong>查看describe表结构</strong></li>
</ol>
<p><code>hbase(main):011:0&gt; describe ‘student’</code>     </p>
<h3 id="4-2-DML操作"><a href="#4-2-DML操作" class="headerlink" title="4.2 DML操作"></a>4.2 DML操作</h3><ol start="5">
<li>更新指定字段的数据（put覆盖即可）</li>
</ol>
<p><code>hbase(main):012:0&gt; put &#39;student&#39;,&#39;1001&#39;,&#39;info:name&#39;,&#39;Nick&#39;</code></p>
<p><code>hbase(main):013:0&gt; put &#39;student&#39;,&#39;1001&#39;,&#39;info:age&#39;,&#39;100&#39;</code></p>
<ol start="6">
<li>查看“指定行”或“指定列族:列”的数据</li>
</ol>
<p><code>hbase(main):014:0&gt; get &#39;student&#39;,&#39;1001&#39;</code></p>
<p><code>hbase(main):015:0&gt; get &#39;student&#39;,&#39;1001&#39;,&#39;info:name&#39;</code></p>
<ol start="7">
<li>统计表数据行数</li>
</ol>
<p><code>hbase(main):021:0&gt; count &#39;student&#39;</code>                  </p>
<ol start="8">
<li>删除数据</li>
</ol>
<p>删除某 rowkey 的<strong>全部</strong>数据：</p>
<p><code>hbase(main):016:0&gt; deleteall &#39;student&#39;,&#39;1001&#39;</code>           </p>
<p>删除某 rowkey 的<strong>某一列</strong>数据：</p>
<p><code>hbase(main):017:0&gt; delete &#39;student&#39;,&#39;1002&#39;,&#39;info:sex&#39;</code></p>
<ol start="9">
<li>清空表数据</li>
</ol>
<p><code>hbase(main):018:0&gt; truncate &#39;student&#39;</code></p>
<p>清空以及删除表的操作顺序为先 disable，然后再truncate和delete。</p>
<ol start="10">
<li>删除表</li>
</ol>
<p><code>hbase(main):019:0&gt; disable &#39;student&#39;</code><br>首先需要先让该表为 disable 状态：然后才能 drop 这个表：</p>
<p><code>hbase(main):020:0&gt; drop &#39;student&#39;</code></p>
<p>提示：如果直接 drop 表，会报错：ERROR: <strong>Table student is enabled. Disable it first.</strong></p>
<p>11．变更表信息</p>
<p>将 info 列族中的数据存放 3 个版本：</p>
<p><code>hbase(main):022:0&gt; alter &#39;student&#39;,{NAME=&gt;&#39;info&#39;,VERSIONS=&gt;3}</code></p>
<p><code>hbase(main):022:0&gt;    get &#39;student&#39;,&#39;1001&#39;,{COLUMN=&gt;&#39;info:name&#39;,VERSIONS=&gt;3}</code></p>
<h2 id="5-HBase架构原理"><a href="#5-HBase架构原理" class="headerlink" title="5. HBase架构原理"></a>5. HBase架构原理</h2><p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625171721.png" alt="2"></p>
<p>1）StoreFile：<strong>实际数据的物理文件</strong>，StoreFile 以 HFile 的形式存储在 <strong>HDFS 上</strong>。每个 Store 会有一个或多个 StoreFile（HFile），数据在每个 StoreFile 中都是有序的。</p>
<p>2）MemStore：写缓存，由于 HFile 中的数据要求是有序的，所以数据是<strong>先存储在 MemStore 中，排好序后，等到达刷写时机才会刷写到HFile，每次刷写都会形成一个新的HFile。</strong></p>
<p>3）WAL：由于数据要经 MemStore 排序后才能刷写到 HFile，但把数据保存在内存中会有很高的概率导致数据丢失，为了解决这个问题，<strong>数据会先写在一个叫做 Write-Ahead logfile 的文件中</strong>，<strong>然后再写入 MemStore 中</strong>。所以在系统出现故障的时候，数据可以通过这个日志文件重建。</p>
<p><strong>总结：数据会先写在一个叫做 Write-Ahead logfile 的文件中</strong>，<strong>然后再写入 MemStore 中排好序后，等到达刷写时机才会刷写到HFile，每次刷写都会形成一个新的HFile。</strong></p>
<h2 id="6-读写流程"><a href="#6-读写流程" class="headerlink" title="6. 读写流程"></a>6. 读写流程</h2><p>（1）写流程</p>
<p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625172116.png" alt="3"></p>
<p>1） Client <strong>先访问 zookeeper</strong>，<strong>获取要查询表的 hbase:meta表 位于的Region Server。</strong></p>
<p>2） 再去访问对应meta表的 Region Server，<strong>获取 hbase:meta 表</strong>，根据读请求的 namespace:table/rowkey， <strong>查询出目标数据位于哪个 Region Server 中的哪个 Region 中。</strong>并将该 <strong>table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache</strong>，方便下次访问。</p>
<p>3） 与目标Region Server 进行通讯，将数据顺序写入（追加）到 WAL；</p>
<p>5） 将数据写入对应的 MemStore，<strong>数据会在 MemStore 进行排序；</strong></p>
<p>6） 向客户端发送ack；</p>
<p>7） 等达到 MemStore 的刷写时机后，<strong>将数据Flush刷写到HFile。</strong></p>
<p>刷写时间：memstroe大小到了，定时器时间到了，wal文件数量到了</p>
<p>（2）读流程</p>
<p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625172036.png" alt="img"></p>
<p>1）Client <strong>先访问 zookeeper</strong>，<strong>获取要查询表的 hbase:meta表 位于的Region Server。</strong></p>
<p>2） 再去访问对应meta表的 Region Server，<strong>获取 hbase:meta 表</strong>，根据读请求的 namespace:table/rowkey， <strong>查询出目标数据位于哪个 Region Server 中的哪个 Region 中。</strong>并将该 <strong>table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache</strong>，方便下次访问。</p>
<p>3） 与目标Region Server 进行通讯；</p>
<p>4） 分别在<strong>Block Cache（读缓存）</strong>，<strong>MemStore</strong> 和 <strong>Store File（HFile）</strong>中查询目标数据</p>
<p>5）由于是分布式存储，所以要将<strong>查到的所有数据进行合并。</strong>此处所有数据是指<strong>同一条数据的不同版本（time stamp）或者不同的类型（Put/Delete）。</strong></p>
<p>6）  将从文件中查询到的数据块（Block，HFile 数据存储单元，默认大小为 64KB）<strong>缓存到Block Cache。</strong></p>
<p>7） <strong>将合并后的最终结果返回给客户端。</strong></p>
<ul>
<li><strong>StoreFile Compaction合并</strong></li>
</ul>
<p>由于<strong>memstore</strong> 每次刷写都会生成一个新的HFile，且同一个字段的不同版本（timestamp）和不同类型（Put/Delete）有可能会分布在不同的HFile 中，因此查询时需要遍历所有的 HFile。<strong>为了减少 HFile 的个数，以及清理掉过期和删除的数据</strong>，会进行 StoreFile Compaction。Compaction 分为两种，分别是 Minor Compaction 和 Major Compaction。</p>
<p><strong>Minor Compaction会将临近的若干个较小的 HFile 合并成一个较大的 HFile，但不会清理过期和删除的数据。</strong></p>
<p><strong>Major Compaction 会将一个 Store 下的所有的 HFile 合并成一个大 HFile，并且会清理掉过期和删除的数据。</strong></p>
<p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625173106.png" alt="4"></p>
<ul>
<li><strong>Region Split拆分</strong></li>
</ul>
<p>默认情况下，每个Table起初只有一个Region，<strong>随着数据的不断写入，Region 会自动进行拆分。</strong>刚拆分时，两个子 Region 都位于当前的 Region Server，但处于负载均衡的考虑，HMaster 有可能会<strong>将某个 Region 转移给其他的 Region Server。</strong></p>
<p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625173058.png" alt="5"></p>
<h2 id="7-JavaAPI操作HBase"><a href="#7-JavaAPI操作HBase" class="headerlink" title="7. JavaAPI操作HBase"></a>7. JavaAPI操作HBase</h2><p>导入HBase的客户端依赖</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><strong>获取 Configuration 配置对象，然后将connection和admin设置为静态变量后期调用。</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// connection是DML的操作对象，来获取表table对象</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Connection connection = <span class="keyword">null</span>;</span><br><span class="line"><span class="comment">// admin是DDL的操作对象</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> Admin admin;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 1.获取配置文件</span></span><br><span class="line">        Configuration conf = HBaseConfiguration.create();</span><br><span class="line">        conf.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"hadoop101,hadoop102,hadoop103"</span>);</span><br><span class="line">        <span class="comment">// 2.获取管理员对象，先拿连接再获取</span></span><br><span class="line">        System.out.println(<span class="string">"连接Hbase..."</span>);</span><br><span class="line">        connection = ConnectionFactory.createConnection(conf);</span><br><span class="line">        admin = connection.getAdmin();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>close方法在最后调用</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (admin != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            admin.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="7-1-DDL的操作"><a href="#7-1-DDL的操作" class="headerlink" title="7.1 DDL的操作"></a>7.1 DDL的操作</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 判断表是否存在</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">isTableExist</span><span class="params">(String tableName)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> admin.tableExists(TableName.valueOf(tableName));</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 创建表</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(String tableName, String... columnFamily)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 1.判断families</span></span><br><span class="line">    <span class="keyword">if</span> (columnFamily.length &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        System.out.println(<span class="string">"无列族信息"</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.判断表是否存在</span></span><br><span class="line">    <span class="keyword">if</span> (isTableExist(tableName)) &#123;</span><br><span class="line">        System.out.println(<span class="string">"表存在"</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 创建表描述器</span></span><br><span class="line">        HTableDescriptor descriptor	= <span class="keyword">new</span> HTableDescriptor(TableName.valueOf(tableName));</span><br><span class="line">        <span class="comment">// 创建多个列族描述器</span></span><br><span class="line">        <span class="keyword">for</span>(String cf : columnFamily) &#123;</span><br><span class="line">            descriptor.addFamily(<span class="keyword">new</span> HColumnDescriptor(cf));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 根据对表的配置，创建表</span></span><br><span class="line">        admin.createTable(descriptor);</span><br><span class="line">        System.out.println(<span class="string">"表"</span> + tableName + <span class="string">"创建成功！"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 删除表</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">drop</span><span class="params">(String tableName)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!isTableExist(tableName)) &#123;</span><br><span class="line">        System.out.println(tableName + <span class="string">"表不存在!"</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 先下线,再删除</span></span><br><span class="line">    admin.disableTable(TableName.valueOf(tableName));</span><br><span class="line">    admin.deleteTable(TableName.valueOf(tableName));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="7-2-DML的操作"><a href="#7-2-DML的操作" class="headerlink" title="7.2 DML的操作"></a>7.2 DML的操作</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 插入数据</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(String tableName, String	rowKey, String columnFamily, String column, String value)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 1.获取表对象, 而不是用admin对象操作</span></span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(tableName));    </span><br><span class="line">        <span class="comment">// 2.创建Put对象</span></span><br><span class="line">        Put put = <span class="keyword">new</span> Put(Bytes.toBytes(rowKey));</span><br><span class="line">        <span class="comment">// 赋值</span></span><br><span class="line">        put.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(column), Bytes.toBytes(value));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3.插入数据</span></span><br><span class="line">        table.put(put);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.关闭表资源</span></span><br><span class="line">        table.close();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 获取数据</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">get</span><span class="params">(String tableName, String rowKey, String columnFamily, String column)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    String value = <span class="string">""</span>;</span><br><span class="line">    <span class="comment">// 1.获取表对象, 而不是用admin对象操作</span></span><br><span class="line">    Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2.获取get对象</span></span><br><span class="line">    Get get = <span class="keyword">new</span> Get(Bytes.toBytes(rowKey));</span><br><span class="line">    <span class="comment">// 只有列族get.addFamily(columnFamily);</span></span><br><span class="line">    get.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(column));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3.获取数据</span></span><br><span class="line">    Result result = table.get(get);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4.遍历结果</span></span><br><span class="line">    <span class="keyword">for</span>(Cell cell : result.rawCells())&#123;</span><br><span class="line">        System.out.print(<span class="string">"列族为"</span> + Bytes.toString(CellUtil.cloneFamily(cell)) + <span class="string">","</span>);</span><br><span class="line">        System.out.print(<span class="string">"列名为"</span> + Bytes.toString(CellUtil.cloneQualifier(cell)) + <span class="string">","</span>);</span><br><span class="line">        value = Bytes.toString(CellUtil.cloneValue(cell));</span><br><span class="line">        System.out.println(<span class="string">"数据为"</span> + value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5.关闭表连接</span></span><br><span class="line">    table.close();</span><br><span class="line">    <span class="keyword">return</span> value;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 获取数据scan</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">scan</span><span class="params">(String tableName, String startRow, String stopRow)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 1.获取表对象, 而不是用admin对象操作</span></span><br><span class="line">    Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">    Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">    scan.setStartRow(Bytes.toBytes(startRow));</span><br><span class="line">    scan.setStopRow(Bytes.toBytes(stopRow));</span><br><span class="line">    ResultScanner scanner = table.getScanner(scan);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (Result result : scanner) &#123;</span><br><span class="line">        <span class="comment">// 4.遍历结果</span></span><br><span class="line">        <span class="keyword">for</span>(Cell cell : result.rawCells()) &#123;</span><br><span class="line">            System.out.print(<span class="string">"rowkey为"</span> + Bytes.toString(CellUtil.cloneRow(cell)) + <span class="string">","</span>);</span><br><span class="line">            System.out.print(<span class="string">"列族为"</span> + Bytes.toString(CellUtil.cloneFamily(cell)) + <span class="string">","</span>);</span><br><span class="line">            System.out.print(<span class="string">"列名为"</span> + Bytes.toString(CellUtil.cloneQualifier(cell)) + <span class="string">","</span>);</span><br><span class="line">            System.out.println(<span class="string">"数据为"</span> + Bytes.toString(CellUtil.cloneValue(cell)));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    table.close();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 删除数据</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">(String tableName, String rowKey, String columnFamily, String column)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 1.获取表对象, 而不是用admin对象操作</span></span><br><span class="line">    Table table = connection.getTable(TableName.valueOf(tableName));</span><br><span class="line"></span><br><span class="line">    Delete delete = <span class="keyword">new</span> Delete(Bytes.toBytes(rowKey));</span><br><span class="line">    delete.addColumn(Bytes.toBytes(columnFamily), Bytes.toBytes(column));</span><br><span class="line"></span><br><span class="line">    table.delete(delete);</span><br><span class="line"></span><br><span class="line">    table.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="二、Hive"><a href="#二、Hive" class="headerlink" title="二、Hive"></a>二、Hive</h1><p>Hive：由 Facebook 开源用于解决海量结构化日志的数据统计工具。 基于 Hadoop 的一个<strong>数据仓库</strong>工具，可以将结构化的数据文件映射为一张表，并提供<strong>类 SQL 查询功能。</strong></p>
<h2 id="1-Hive本质"><a href="#1-Hive本质" class="headerlink" title="1. Hive本质"></a>1. Hive本质</h2><p><strong>Hive 本质：将 HQL 转化成 MapReduce 程序</strong>，避免了去写 MapReduce，减少开发人员的学习成本。</p>
<p>注意：由于 Hive 是针对数据仓库应用设计的，<strong>而数据仓库的内容是读多写少的</strong>。因此，Hive 中不建议对数据的改写，所有的数据都是在加载的时候确定好的。</p>
<p>（1） Hive 处理的<strong>数据存储在 HDFS</strong></p>
<p>（2） Hive <strong>分析数据底层的实现是 MapReduce</strong></p>
<p>（3） <strong>执行程序运行在 Yarn 上</strong></p>
<p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625183331.png" alt="1"></p>
<h2 id="2-架构原理"><a href="#2-架构原理" class="headerlink" title="2. 架构原理"></a>2. 架构原理</h2><p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625183733.png" alt="img"></p>
<p>1） 用户接口：Client就是一些命令行CLI（command-line interface）、JDBC/ODBC(jdbc 访问 hive)、WEBUI（浏览器访问 hive）</p>
<p>2）<strong>元数据Metastore：包括：表名、表所属的数据库（默认是 default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；</strong></p>
<p>Hive表中的数据是HDFS上的文件，可是Hive怎么知道这些文件的内容都对应哪个字段，对应哪个分区呢？</p>
<p><img src="https://gitee.com/rnang0/blogimage/raw/master/20210625185358.png" alt="img"></p>
<p>默认存储在自带的 derby 数据库中，推荐使用 MySQL 存储Metastore</p>
<p>3）驱动器：Driver</p>
<p>（1）解析器（SQL Parser）：将 SQL 字符串转换成抽象语法树 AST，这一步一般都用第三方工具库完成，比如 antlr；对 AST 进行语法分析，比如表是否存在、字段是否存在、SQL 语义是否有误。</p>
<p>（2）编译器（Physical Plan）：将 AST 编译生成逻辑执行计划。</p>
<p>（3）优化器（Query Optimizer）：对逻辑执行计划进行优化。</p>
<p>（4）执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。</p>
<p><strong>对于 Hive 来说，就是 MR/Spark。</strong></p>
<p>4）Hadoop使用 HDFS 进行存储，使用 MapReduce 进行计算。</p>
<h2 id="3-Hive数据类型"><a href="#3-Hive数据类型" class="headerlink" title="3. Hive数据类型"></a>3. Hive数据类型</h2><table>
<thead>
<tr>
<th>Hive 数据类型</th>
<th>Java 数据类型</th>
<th>长度</th>
<th>例子</th>
</tr>
</thead>
<tbody><tr>
<td>TINYINT</td>
<td>byte</td>
<td>1byte 有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>SMALINT</td>
<td>short</td>
<td>2byte 有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>INT</td>
<td>int</td>
<td>4byte 有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>BIGINT</td>
<td>long</td>
<td>8byte 有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>BOOLEAN</td>
<td>boolean</td>
<td>布尔类型，true 或者  false</td>
<td>TRUE FALSE</td>
</tr>
<tr>
<td>FLOAT</td>
<td>float</td>
<td>单精度浮点数</td>
<td>3.14159</td>
</tr>
<tr>
<td>DOUBLE</td>
<td>double</td>
<td>双精度浮点数</td>
<td>3.14159</td>
</tr>
<tr>
<td>STRING</td>
<td>string</td>
<td>字符系列。可以指定字符集。可以使用单引号或者双  引号。</td>
<td>‘ now is the time ’ “for all good men”</td>
</tr>
<tr>
<td>TIMESTAMP</td>
<td></td>
<td>时间类型</td>
<td></td>
</tr>
<tr>
<td>BINARY</td>
<td></td>
<td>字节数组</td>
<td></td>
</tr>
</tbody></table>
<p>对于 Hive 的 <strong>String 类型相当于数据库的varchar 类型</strong>，该类型是一个可变的字符串，不过它不能声明其中最多能存储多少个字符，理论上它可以存储 2GB 的字符数。</p>
<h2 id="4-DDL操作"><a href="#4-DDL操作" class="headerlink" title="4. DDL操作"></a>4. DDL操作</h2><ul>
<li>创建数据库</li>
</ul>
<p><strong>创建一个数据库，数据库在 HDFS 上的默认存储路径是/user/hive/warehouse/*.db。</strong></p>
<ul>
<li>显示数据库</li>
</ul>
<p><strong>hive&gt; show databases;</strong></p>
<ul>
<li><p>显示数据库信息<code>desc database db_hive;</code></p>
</li>
<li><p>显示数据库详细信息，<code>desc database extended db_hive;</code></p>
</li>
<li><p>切换当前数据库<code>use db_hive;</code></p>
</li>
<li><p>删除数据库<code>drop database db_hive cascade;</code></p>
</li>
<li><p>创建表</p>
</li>
</ul>
<p>create table 表名(字段1 类型, 字段2 类型, ……) <strong>row format delimited fields terminated by ‘\t’</strong> location ‘/data’;</p>
<p>例如：分别<strong>创建部门和员工外部表</strong>，并向表中<strong>导入数据。</strong></p>
<p>（1）上传数据到 HDFS</p>
<p><code>hive (default)&gt; dfs -mkdir /student;</code></p>
<p><code>hive (default)&gt; dfs -put /opt/module/datas/student.txt /student;</code></p>
<p>（2） 建表语句，创建外部表创建部门表</p>
<p><code>create external table if not exists emp( empno int, ename string, job string, mgr int, hiredate string, sal double, comm double, deptno int) row format delimited fields terminated by &#39;\t&#39;;</code></p>
<p><code>create external table if not exists dept( deptno int, dname string, loc int) row format delimited fields terminated by &#39;\t&#39;;</code></p>
<p>（3）增加列</p>
<p><code>hive (default)&gt; alter table dept add columns(deptdesc string);</code></p>
<h2 id="5-DML操作"><a href="#5-DML操作" class="headerlink" title="5. DML操作"></a>5. DML操作</h2><ul>
<li>数据导入</li>
</ul>
<p><code>load data local inpath &#39;/opt/module/hive/datas/student.txt&#39; into table default.student;</code></p>
<p><code>dfs -put /opt/module/hive/data/student.txt /user/yangyifan/hive;</code></p>
<ul>
<li>数据插入</li>
</ul>
<p><code>insert into table student_par values(1,&#39;wangwu&#39;),(2,&#39;zhaoliu&#39;);</code></p>
<ul>
<li>创建表时通过Location指定加载数据路径</li>
</ul>
<p><code>create external table if not exists student5( id int, name string) row format delimited fields terminated by &#39;\t&#39; location &#39;/student;</code></p>
<ul>
<li>查询</li>
</ul>
<p><code>select * from student5;</code></p>
<h2 id="HBase-与-Hive-的对比"><a href="#HBase-与-Hive-的对比" class="headerlink" title="HBase 与 Hive 的对比"></a>HBase 与 Hive 的对比</h2><ol>
<li>Hive</li>
</ol>
<p>(1)  数据仓库</p>
<p>Hive 的本质其实就相当于将 <strong>HDFS 中已经存储的文件在 Mysql 中做了一个双射关系</strong>，以<strong>方便使用HQL去管理查询。</strong></p>
<p>(2)  用于数据分析、清洗</p>
<p>Hive 适用于离线的数据分析和清洗，延迟较高。</p>
<p>(3)  基于HDFS、MapReduce</p>
<p>Hive 存储的数据依旧在DataNode 上，<strong>编写的HQL 语句终将是转换为 MapReduce 代码执行。</strong></p>
<ol start="2">
<li>HBase</li>
</ol>
<p>(1)  数据库</p>
<p>是一种面向列族存储的<strong>非关系型数据库。</strong></p>
<p>(2)  用于存储结构化和非结构化的数据</p>
<p>适用于单表非关系型数据的存储，不适合做关联查询，类似 JOIN 等操作。</p>
<p>(3)  基于HDFS</p>
<p><strong>数据持久化存储的体现形式是HFile</strong>，存放于 DataNode 中，被 ResionServer 以 region 的形式进行管理。</p>
<p>(4)  延迟较低，接入在线业务使用</p>
<p>面对大量的企业数据，HBase 可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">rnang0</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://rnang0.github.io/2021/06/09/HBase/">http://rnang0.github.io/2021/06/09/HBase/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://rnang0.github.io" target="_blank">rnang0 Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/HBase/">HBase</a><a class="post-meta__tags" href="/tags/Hive/">Hive</a></div><div class="post_share"><div class="social-share" data-image="https://gitee.com/rnang0/blogimage/raw/master/20210625163109.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2021/05/08/Hadoop/"><img class="next_cover" src="https://gitee.com/rnang0/blogimage/raw/master/20210508224446.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">大数据Hadoop</div></div></a></div></nav></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By rnang0</div><div class="footer_custom_text">Hi, welcome to my <a href="http://rnang0.github.io/">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script></body></html>